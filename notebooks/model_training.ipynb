{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed274eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e972f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manth\\AppData\\Local\\Temp\\ipykernel_13056\\2540032479.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  data=pd.read_csv(\"../artifacts/data/sp500.csv\",skipfooter=40000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close    volume Name\n",
       "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../artifacts/data/sp500.csv\",skipfooter=40000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0114be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    10000 non-null  object \n",
      " 1   open    10000 non-null  float64\n",
      " 2   high    10000 non-null  float64\n",
      " 3   low     10000 non-null  float64\n",
      " 4   close   10000 non-null  float64\n",
      " 5   volume  10000 non-null  int64  \n",
      " 6   Name    10000 non-null  object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fecaa3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.409088</td>\n",
       "      <td>82.164968</td>\n",
       "      <td>80.663020</td>\n",
       "      <td>81.443147</td>\n",
       "      <td>1.092780e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.828416</td>\n",
       "      <td>38.119626</td>\n",
       "      <td>37.523002</td>\n",
       "      <td>37.836402</td>\n",
       "      <td>2.072435e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.140000</td>\n",
       "      <td>13.420000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>13.020000</td>\n",
       "      <td>1.307120e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.740000</td>\n",
       "      <td>49.183750</td>\n",
       "      <td>48.280000</td>\n",
       "      <td>48.677500</td>\n",
       "      <td>1.897144e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.075000</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>75.485050</td>\n",
       "      <td>76.145000</td>\n",
       "      <td>4.015270e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>105.742500</td>\n",
       "      <td>106.825000</td>\n",
       "      <td>104.861250</td>\n",
       "      <td>105.862500</td>\n",
       "      <td>8.631211e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>201.240000</td>\n",
       "      <td>201.240000</td>\n",
       "      <td>198.160000</td>\n",
       "      <td>200.380000</td>\n",
       "      <td>2.668336e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open          high           low         close        volume\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  1.000000e+04\n",
       "mean      81.409088     82.164968     80.663020     81.443147  1.092780e+07\n",
       "std       37.828416     38.119626     37.523002     37.836402  2.072435e+07\n",
       "min       13.140000     13.420000     12.700000     13.020000  1.307120e+05\n",
       "25%       48.740000     49.183750     48.280000     48.677500  1.897144e+06\n",
       "50%       76.075000     76.800000     75.485050     76.145000  4.015270e+06\n",
       "75%      105.742500    106.825000    104.861250    105.862500  8.631211e+06\n",
       "max      201.240000    201.240000    198.160000    200.380000  2.668336e+08"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d63da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "Name      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa73d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "open      0\n",
       "high      0\n",
       "low       0\n",
       "close     0\n",
       "volume    0\n",
       "Name      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(strategy='mean')\n",
    "data['open']=imputer.fit_transform(data[['open']])\n",
    "data['high']=imputer.fit_transform(data[['high']])\n",
    "data['low']=imputer.fit_transform(data[['low']])\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45ba4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3557c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "data['Name']=encoder.fit_transform(data['Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74a14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Day, month, year\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day'] = data['date'].dt.day\n",
    "\n",
    "# Day of the week (0 = Monday, 6 = Sunday)\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "\n",
    "# Week of the year\n",
    "data['week_of_year'] = data['date'].dt.isocalendar().week\n",
    "\n",
    "# Quarter of the year\n",
    "data['quarter'] = data['date'].dt.quarter\n",
    "\n",
    "# Is month start/end\n",
    "data['is_month_start'] = data['date'].dt.is_month_start.astype(int)\n",
    "data['is_month_end'] = data['date'].dt.is_month_end.astype(int)\n",
    "\n",
    "# Is quarter start/end\n",
    "data['is_quarter_start'] = data['date'].dt.is_quarter_start.astype(int)\n",
    "data['is_quarter_end'] = data['date'].dt.is_quarter_end.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12c6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['open', 'high', 'low', 'close']\n",
    "windows = [5, 10, 20]\n",
    "\n",
    "for col in cols:\n",
    "    for w in windows:\n",
    "        data[f'{col}_EMA_{w}'] = data[col].ewm(span=w, adjust=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a2d3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>open_EMA_20</th>\n",
       "      <th>high_EMA_5</th>\n",
       "      <th>high_EMA_10</th>\n",
       "      <th>high_EMA_20</th>\n",
       "      <th>low_EMA_5</th>\n",
       "      <th>low_EMA_10</th>\n",
       "      <th>low_EMA_20</th>\n",
       "      <th>close_EMA_5</th>\n",
       "      <th>close_EMA_10</th>\n",
       "      <th>close_EMA_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>15.070000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>14.630000</td>\n",
       "      <td>14.630000</td>\n",
       "      <td>14.630000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>14.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>15.052857</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>15.109524</td>\n",
       "      <td>14.506667</td>\n",
       "      <td>14.562727</td>\n",
       "      <td>14.594762</td>\n",
       "      <td>14.653333</td>\n",
       "      <td>14.697273</td>\n",
       "      <td>14.722381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>14.995442</td>\n",
       "      <td>14.892222</td>\n",
       "      <td>14.992727</td>\n",
       "      <td>15.052426</td>\n",
       "      <td>14.371111</td>\n",
       "      <td>14.478595</td>\n",
       "      <td>14.547642</td>\n",
       "      <td>14.525556</td>\n",
       "      <td>14.619587</td>\n",
       "      <td>14.679297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>14.929210</td>\n",
       "      <td>14.908148</td>\n",
       "      <td>14.983140</td>\n",
       "      <td>15.041719</td>\n",
       "      <td>14.330741</td>\n",
       "      <td>14.437032</td>\n",
       "      <td>14.519295</td>\n",
       "      <td>14.570370</td>\n",
       "      <td>14.626935</td>\n",
       "      <td>14.677459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>14.930237</td>\n",
       "      <td>14.925432</td>\n",
       "      <td>14.978933</td>\n",
       "      <td>15.033936</td>\n",
       "      <td>13.940494</td>\n",
       "      <td>14.204845</td>\n",
       "      <td>14.389838</td>\n",
       "      <td>14.376914</td>\n",
       "      <td>14.511128</td>\n",
       "      <td>14.611987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume  Name  year  month  day  \\\n",
       "0 2013-02-08  15.07  15.12  14.63  14.75   8407500     0  2013      2    8   \n",
       "1 2013-02-11  14.89  15.01  14.26  14.46   8882000     0  2013      2   11   \n",
       "2 2013-02-12  14.45  14.51  14.10  14.27   8126000     0  2013      2   12   \n",
       "3 2013-02-13  14.30  14.94  14.25  14.66  10259500     0  2013      2   13   \n",
       "4 2013-02-14  14.94  14.96  13.16  13.99  31879900     0  2013      2   14   \n",
       "\n",
       "   ...  open_EMA_20  high_EMA_5  high_EMA_10  high_EMA_20  low_EMA_5  \\\n",
       "0  ...    15.070000   15.120000    15.120000    15.120000  14.630000   \n",
       "1  ...    15.052857   15.083333    15.100000    15.109524  14.506667   \n",
       "2  ...    14.995442   14.892222    14.992727    15.052426  14.371111   \n",
       "3  ...    14.929210   14.908148    14.983140    15.041719  14.330741   \n",
       "4  ...    14.930237   14.925432    14.978933    15.033936  13.940494   \n",
       "\n",
       "   low_EMA_10  low_EMA_20  close_EMA_5  close_EMA_10  close_EMA_20  \n",
       "0   14.630000   14.630000    14.750000     14.750000     14.750000  \n",
       "1   14.562727   14.594762    14.653333     14.697273     14.722381  \n",
       "2   14.478595   14.547642    14.525556     14.619587     14.679297  \n",
       "3   14.437032   14.519295    14.570370     14.626935     14.677459  \n",
       "4   14.204845   14.389838    14.376914     14.511128     14.611987  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e3ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns=['date','close']).values\n",
    "Y=data['close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965d8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd6e3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "328893fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression ,Ridge , Lasso, ElasticNet    \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "\n",
    "# XGBoost, LightGBM, CatBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7baa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(),\n",
    "    \"BaggingRegressor\": BaggingRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(objective='reg:squarederror'),\n",
    "    \"LGBMRegressor\": LGBMRegressor(),\n",
    "    \"CatBoostRegressor\": CatBoostRegressor(verbose=0),\n",
    "    \"SVR\": SVR(),\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "\n",
    "    \"Ridge\": {\n",
    "        \"alpha\": [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sag\", \"saga\"]\n",
    "    },\n",
    "\n",
    "    \"Lasso\": {\n",
    "        \"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        \"selection\": [\"cyclic\", \"random\"]\n",
    "    },\n",
    "\n",
    "    \"ElasticNet\": {\n",
    "        \"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    },\n",
    "\n",
    "    \"KNeighborsRegressor\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 15],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"p\": [1, 2]  # 1=Manhattan, 2=Euclidean\n",
    "    },\n",
    "\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\"],\n",
    "        \"splitter\": [\"best\", \"random\"],\n",
    "        \"max_depth\": [None, 5, 10, 20, 50],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 5, 10]\n",
    "    },\n",
    "\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
    "        \"max_depth\": [None, 10, 20, 50],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "    },\n",
    "\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"max_depth\": [3, 5, 10],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4]\n",
    "    },\n",
    "\n",
    "    \"AdaBoostRegressor\": {\n",
    "        \"n_estimators\": [50, 100, 200, 500],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.5, 1.0],\n",
    "        \"loss\": [\"linear\", \"square\", \"exponential\"]\n",
    "    },\n",
    "\n",
    "    \"BaggingRegressor\": {\n",
    "        \"n_estimators\": [10, 50, 100, 200],\n",
    "        \"max_samples\": [0.5, 0.7, 1.0],\n",
    "        \"max_features\": [0.5, 0.7, 1.0],\n",
    "        \"bootstrap\": [True, False]\n",
    "    },\n",
    "\n",
    "    \"XGBRegressor\": {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7, 10],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"gamma\": [0, 0.1, 0.2, 0.3],\n",
    "        \"reg_alpha\": [0, 0.01, 0.1, 1],\n",
    "        \"reg_lambda\": [0.1, 1.0, 10.0]\n",
    "    },\n",
    "\n",
    "    \"LGBMRegressor\": {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"num_leaves\": [31, 50, 100],\n",
    "        \"max_depth\": [-1, 5, 10, 20],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"reg_alpha\": [0, 0.01, 0.1],\n",
    "        \"reg_lambda\": [0, 0.1, 1.0]\n",
    "    },\n",
    "    \n",
    "    \"CatBoostRegressor\": {\n",
    "        \"iterations\": [200, 500, 1000],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"depth\": [4, 6, 8, 10],\n",
    "        \"l2_leaf_reg\": [1, 3, 5, 7],\n",
    "        \"bagging_temperature\": [0, 0.5, 1.0]\n",
    "    },\n",
    "    \n",
    "\n",
    "    \"SVR\": {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"degree\": [2, 3, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c192f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "result={}\n",
    "def model_training(models,param_grids,x_train,y_train,x_test,y_test):\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        param_grid = param_grids.get(name, {})\n",
    "        if param_grid:\n",
    "            grid_search = RandomizedSearchCV(model, param_grid, cv=2, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "            grid_search.fit(x_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            print(f\"Best parameters for {name}: {best_params}\")\n",
    "        else:\n",
    "            model.fit(x_train, y_train)\n",
    "            best_model = model\n",
    "            best_params = \"Default parameters used\"\n",
    "        \n",
    "        y_pred = best_model.predict(x_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        result[name] = {\n",
    "            'model': best_model,\n",
    "            'best_params': best_params,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} - MSE: {mse}, MAE: {mae}, R2: {r2}\\n\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06f24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearRegression...\n",
      "LinearRegression - MSE: 0.04927540612668112, MAE: 0.16350980697370893, R2: 0.9999424387088994\n",
      "\n",
      "Training Ridge...\n",
      "Best parameters for Ridge: {'solver': 'svd', 'alpha': 0.01}\n",
      "Ridge - MSE: 0.07957917376549627, MAE: 0.20347482330981786, R2: 0.9999070392240932\n",
      "\n",
      "Training Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.987e+03, tolerance: 1.203e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Lasso: {'selection': 'random', 'alpha': 0.01}\n",
      "Lasso - MSE: 0.7000205384841668, MAE: 0.5553857429382325, R2: 0.9991822678053938\n",
      "\n",
      "Training ElasticNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+03, tolerance: 1.203e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for ElasticNet: {'l1_ratio': 0.7, 'alpha': 0.001}\n",
      "ElasticNet - MSE: 0.5557524610375959, MAE: 0.5406056345057181, R2: 0.9993507952200857\n",
      "\n",
      "Training KNeighborsRegressor...\n",
      "Best parameters for KNeighborsRegressor: {'weights': 'uniform', 'p': 1, 'n_neighbors': 3}\n",
      "KNeighborsRegressor - MSE: 9.200761804671668, MAE: 2.16785605, R2: 0.9892520880046244\n",
      "\n",
      "Training DecisionTreeRegressor...\n",
      "Best parameters for DecisionTreeRegressor: {'splitter': 'random', 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 10, 'criterion': 'squared_error'}\n",
      "DecisionTreeRegressor - MSE: 2.8944582545070805, MAE: 0.6881332458332997, R2: 0.9966188253479256\n",
      "\n",
      "Training RandomForestRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "8 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [          nan -233.08022381           nan -242.37759135 -226.66956267\n",
      " -228.83574375           nan           nan -237.90709756 -242.41463591]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForestRegressor: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'squared_error'}\n",
      "RandomForestRegressor - MSE: 1.1211083386903364, MAE: 0.5679363972834883, R2: 0.9986903721651171\n",
      "\n",
      "Training GradientBoostingRegressor...\n",
      "Best parameters for GradientBoostingRegressor: {'subsample': 0.8, 'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "GradientBoostingRegressor - MSE: 0.27917943997020006, MAE: 0.3930500711894422, R2: 0.9996738752599601\n",
      "\n",
      "Training AdaBoostRegressor...\n",
      "Best parameters for AdaBoostRegressor: {'n_estimators': 100, 'loss': 'square', 'learning_rate': 1.0}\n",
      "AdaBoostRegressor - MSE: 1.884724423987958, MAE: 1.1021319998321515, R2: 0.9977983505415527\n",
      "\n",
      "Training BaggingRegressor...\n",
      "Best parameters for BaggingRegressor: {'n_estimators': 10, 'max_samples': 0.7, 'max_features': 0.7, 'bootstrap': True}\n",
      "BaggingRegressor - MSE: 0.37193986463099965, MAE: 0.45551642999999953, R2: 0.999565516745516\n",
      "\n",
      "Training XGBRegressor...\n",
      "Best parameters for XGBRegressor: {'subsample': 0.8, 'reg_lambda': 0.1, 'reg_alpha': 0.01, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "XGBRegressor - MSE: 0.7004807317619095, MAE: 0.636370504397583, R2: 0.999181730228511\n",
      "\n",
      "Training LGBMRegressor...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4217\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 77.676174\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters for LGBMRegressor: {'subsample': 0.8, 'reg_lambda': 0, 'reg_alpha': 0, 'num_leaves': 31, 'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "LGBMRegressor - MSE: 0.4023509987382713, MAE: 0.4809229869902516, R2: 0.9995299918400784\n",
      "\n",
      "Training CatBoostRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Portfolio Project\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for CatBoostRegressor: {'learning_rate': 0.01, 'l2_leaf_reg': 5, 'iterations': 1000, 'depth': 4, 'bagging_temperature': 1.0}\n",
      "CatBoostRegressor - MSE: 2.101742193373927, MAE: 0.9946883986581477, R2: 0.9975448402413938\n",
      "\n",
      "Training SVR...\n",
      "Best parameters for SVR: {'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'C': 10}\n",
      "SVR - MSE: 0.16379049225141026, MAE: 0.22985696128343172, R2: 0.9998086673871392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': {'model': LinearRegression(),\n",
       "  'best_params': 'Default parameters used',\n",
       "  'mse': 0.04927540612668112,\n",
       "  'mae': 0.16350980697370893,\n",
       "  'r2': 0.9999424387088994},\n",
       " 'Ridge': {'model': Ridge(alpha=0.01, solver='svd'),\n",
       "  'best_params': {'solver': 'svd', 'alpha': 0.01},\n",
       "  'mse': 0.07957917376549627,\n",
       "  'mae': 0.20347482330981786,\n",
       "  'r2': 0.9999070392240932},\n",
       " 'Lasso': {'model': Lasso(alpha=0.01, selection='random'),\n",
       "  'best_params': {'selection': 'random', 'alpha': 0.01},\n",
       "  'mse': 0.7000205384841668,\n",
       "  'mae': 0.5553857429382325,\n",
       "  'r2': 0.9991822678053938},\n",
       " 'ElasticNet': {'model': ElasticNet(alpha=0.001, l1_ratio=0.7),\n",
       "  'best_params': {'l1_ratio': 0.7, 'alpha': 0.001},\n",
       "  'mse': 0.5557524610375959,\n",
       "  'mae': 0.5406056345057181,\n",
       "  'r2': 0.9993507952200857},\n",
       " 'KNeighborsRegressor': {'model': KNeighborsRegressor(n_neighbors=3, p=1),\n",
       "  'best_params': {'weights': 'uniform', 'p': 1, 'n_neighbors': 3},\n",
       "  'mse': 9.200761804671668,\n",
       "  'mae': 2.16785605,\n",
       "  'r2': 0.9892520880046244},\n",
       " 'DecisionTreeRegressor': {'model': DecisionTreeRegressor(max_depth=10, min_samples_leaf=2, min_samples_split=5,\n",
       "                        splitter='random'),\n",
       "  'best_params': {'splitter': 'random',\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 10,\n",
       "   'criterion': 'squared_error'},\n",
       "  'mse': 2.8944582545070805,\n",
       "  'mae': 0.6881332458332997,\n",
       "  'r2': 0.9966188253479256},\n",
       " 'RandomForestRegressor': {'model': RandomForestRegressor(max_depth=10, max_features='log2', n_estimators=500),\n",
       "  'best_params': {'n_estimators': 500,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 10,\n",
       "   'criterion': 'squared_error'},\n",
       "  'mse': 1.1211083386903364,\n",
       "  'mae': 0.5679363972834883,\n",
       "  'r2': 0.9986903721651171},\n",
       " 'GradientBoostingRegressor': {'model': GradientBoostingRegressor(learning_rate=0.05, max_depth=10, min_samples_leaf=2,\n",
       "                            min_samples_split=5, n_estimators=500, subsample=0.8),\n",
       "  'best_params': {'subsample': 0.8,\n",
       "   'n_estimators': 500,\n",
       "   'min_samples_split': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.05},\n",
       "  'mse': 0.27917943997020006,\n",
       "  'mae': 0.3930500711894422,\n",
       "  'r2': 0.9996738752599601},\n",
       " 'AdaBoostRegressor': {'model': AdaBoostRegressor(loss='square', n_estimators=100),\n",
       "  'best_params': {'n_estimators': 100, 'loss': 'square', 'learning_rate': 1.0},\n",
       "  'mse': 1.884724423987958,\n",
       "  'mae': 1.1021319998321515,\n",
       "  'r2': 0.9977983505415527},\n",
       " 'BaggingRegressor': {'model': BaggingRegressor(max_features=0.7, max_samples=0.7),\n",
       "  'best_params': {'n_estimators': 10,\n",
       "   'max_samples': 0.7,\n",
       "   'max_features': 0.7,\n",
       "   'bootstrap': True},\n",
       "  'mse': 0.37193986463099965,\n",
       "  'mae': 0.45551642999999953,\n",
       "  'r2': 0.999565516745516},\n",
       " 'XGBRegressor': {'model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=0, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       "  'best_params': {'subsample': 0.8,\n",
       "   'reg_lambda': 0.1,\n",
       "   'reg_alpha': 0.01,\n",
       "   'n_estimators': 200,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.2,\n",
       "   'gamma': 0,\n",
       "   'colsample_bytree': 0.6},\n",
       "  'mse': 0.7004807317619095,\n",
       "  'mae': 0.636370504397583,\n",
       "  'r2': 0.999181730228511},\n",
       " 'LGBMRegressor': {'model': LGBMRegressor(max_depth=20, n_estimators=500, reg_alpha=0, reg_lambda=0,\n",
       "                subsample=0.8),\n",
       "  'best_params': {'subsample': 0.8,\n",
       "   'reg_lambda': 0,\n",
       "   'reg_alpha': 0,\n",
       "   'num_leaves': 31,\n",
       "   'n_estimators': 500,\n",
       "   'max_depth': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  'mse': 0.4023509987382713,\n",
       "  'mae': 0.4809229869902516,\n",
       "  'r2': 0.9995299918400784},\n",
       " 'CatBoostRegressor': {'model': <catboost.core.CatBoostRegressor at 0x1e514c10f70>,\n",
       "  'best_params': {'learning_rate': 0.01,\n",
       "   'l2_leaf_reg': 5,\n",
       "   'iterations': 1000,\n",
       "   'depth': 4,\n",
       "   'bagging_temperature': 1.0},\n",
       "  'mse': 2.101742193373927,\n",
       "  'mae': 0.9946883986581477,\n",
       "  'r2': 0.9975448402413938},\n",
       " 'SVR': {'model': SVR(C=10, degree=4, gamma='auto', kernel='linear'),\n",
       "  'best_params': {'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'C': 10},\n",
       "  'mse': 0.16379049225141026,\n",
       "  'mae': 0.22985696128343172,\n",
       "  'r2': 0.9998086673871392}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_training(models,param_grids,x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "327be983",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters={}\n",
    "for i in result.keys():\n",
    "    best_parameters[i]=result[i]['best_params']\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f20262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 'Default parameters used',\n",
       " 'Ridge': {'solver': 'svd', 'alpha': 0.01},\n",
       " 'Lasso': {'selection': 'random', 'alpha': 0.01},\n",
       " 'ElasticNet': {'l1_ratio': 0.7, 'alpha': 0.001},\n",
       " 'KNeighborsRegressor': {'weights': 'uniform', 'p': 1, 'n_neighbors': 3},\n",
       " 'DecisionTreeRegressor': {'splitter': 'random',\n",
       "  'min_samples_split': 5,\n",
       "  'min_samples_leaf': 2,\n",
       "  'max_depth': 10,\n",
       "  'criterion': 'squared_error'},\n",
       " 'RandomForestRegressor': {'n_estimators': 500,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 1,\n",
       "  'max_features': 'log2',\n",
       "  'max_depth': 10,\n",
       "  'criterion': 'squared_error'},\n",
       " 'GradientBoostingRegressor': {'subsample': 0.8,\n",
       "  'n_estimators': 500,\n",
       "  'min_samples_split': 5,\n",
       "  'min_samples_leaf': 2,\n",
       "  'max_depth': 10,\n",
       "  'learning_rate': 0.05},\n",
       " 'AdaBoostRegressor': {'n_estimators': 100,\n",
       "  'loss': 'square',\n",
       "  'learning_rate': 1.0},\n",
       " 'BaggingRegressor': {'n_estimators': 10,\n",
       "  'max_samples': 0.7,\n",
       "  'max_features': 0.7,\n",
       "  'bootstrap': True},\n",
       " 'XGBRegressor': {'subsample': 0.8,\n",
       "  'reg_lambda': 0.1,\n",
       "  'reg_alpha': 0.01,\n",
       "  'n_estimators': 200,\n",
       "  'max_depth': 3,\n",
       "  'learning_rate': 0.2,\n",
       "  'gamma': 0,\n",
       "  'colsample_bytree': 0.6},\n",
       " 'LGBMRegressor': {'subsample': 0.8,\n",
       "  'reg_lambda': 0,\n",
       "  'reg_alpha': 0,\n",
       "  'num_leaves': 31,\n",
       "  'n_estimators': 500,\n",
       "  'max_depth': 20,\n",
       "  'learning_rate': 0.1,\n",
       "  'colsample_bytree': 1.0},\n",
       " 'CatBoostRegressor': {'learning_rate': 0.01,\n",
       "  'l2_leaf_reg': 5,\n",
       "  'iterations': 1000,\n",
       "  'depth': 4,\n",
       "  'bagging_temperature': 1.0},\n",
       " 'SVR': {'kernel': 'linear', 'gamma': 'auto', 'degree': 4, 'C': 10}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5c663a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../artifacts/best_params/best_params.json', 'w') as f:\n",
    "    json.dump(best_parameters, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3f789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
